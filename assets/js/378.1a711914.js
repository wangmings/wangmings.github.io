(window.webpackJsonp=window.webpackJsonp||[]).push([[378],{873:function(a,s,r){"use strict";r.r(s);var t=r(30),e=Object(t.a)({},(function(){var a=this,s=a.$createElement,r=a._self._c||s;return r("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[r("h2",{attrs:{id:"scrapy的crawlspider爬虫"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#scrapy的crawlspider爬虫"}},[a._v("#")]),a._v(" scrapy的crawlspider爬虫")]),a._v(" "),r("h5",{attrs:{id:"学习目标"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[a._v("#")]),a._v(" 学习目标：")]),a._v(" "),r("ol",[r("li",[a._v("了解 crawlspider的作用")]),a._v(" "),r("li",[a._v("应用 crawlspider爬虫创建的方法")]),a._v(" "),r("li",[a._v("应用 crawlspider中rules的使用")])]),a._v(" "),r("hr"),a._v(" "),r("h3",{attrs:{id:"_1-crawlspider是什么"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-crawlspider是什么"}},[a._v("#")]),a._v(" 1 crawlspider是什么")]),a._v(" "),r("blockquote",[r("p",[a._v("回顾之前的代码中，我们有很大一部分时间在寻找下一页的url地址或者是内容的url地址上面，这个过程能更简单一些么？")])]),a._v(" "),r("h5",{attrs:{id:"思路"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#思路"}},[a._v("#")]),a._v(" 思路：")]),a._v(" "),r("ol",[r("li",[a._v("从response中提取所有的满足规则的url地址")]),a._v(" "),r("li",[a._v("自动的构造自己requests请求，发送给引擎")])]),a._v(" "),r("p",[a._v("对应的"),r("strong",[a._v("crawlspider就可以实现上述需求，能够匹配满足条件的url地址，组装成Reuqest对象后自动发送给引擎，同时能够指定callback函数")])]),a._v(" "),r("p",[r("strong",[a._v("即：crawlspider爬虫可以按照规则自动获取连接")])]),a._v(" "),r("h3",{attrs:{id:"_2-创建crawlspider爬虫并观察爬虫内的默认内容"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-创建crawlspider爬虫并观察爬虫内的默认内容"}},[a._v("#")]),a._v(" 2 创建crawlspider爬虫并观察爬虫内的默认内容")]),a._v(" "),r("h5",{attrs:{id:"_2-1-创建crawlspider爬虫"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-创建crawlspider爬虫"}},[a._v("#")]),a._v(" 2.1 创建crawlspider爬虫：")]),a._v(" "),r("p",[r("code",[a._v("scrapy genspider \\-t crawl tencent hr.tencent.com")])]),a._v(" "),r("h5",{attrs:{id:"_2-2-spider中默认生成的内容如下"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-spider中默认生成的内容如下"}},[a._v("#")]),a._v(" 2.2 spider中默认生成的内容如下：")]),a._v(" "),r("div",{staticClass:"language-Python line-numbers-mode"},[r("pre",{pre:!0,attrs:{class:"language-python"}},[r("code",[r("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("class")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("TencentSpider")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("CrawlSpider"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n    name "),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token string"}},[a._v("'itcast1'")]),a._v("\n    allowed_domains "),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[a._v("'hr.tencent.com'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n    start_urls "),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),r("span",{pre:!0,attrs:{class:"token string"}},[a._v("'http://hr.tencent.com'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n    rules "),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("\n        Rule"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("LinkExtractor"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("allow"),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[a._v("r'Items/'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" callback"),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[a._v("'parse_item'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" follow"),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),r("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("True")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n    "),r("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("def")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token function"}},[a._v("parse_item")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("self"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" response"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),a._v("\n        i "),r("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n        "),r("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#i['domain_id'] = response.xpath('//input[@id=\"sid\"]/@value').extract()")]),a._v("\n        "),r("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#i['name'] = response.xpath('//div[@id=\"name\"]').extract()")]),a._v("\n        "),r("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#i['description'] = response.xpath('//div[@id=\"description\"]').extract()")]),a._v("\n        "),r("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("return")]),a._v(" i \n")])]),a._v(" "),r("div",{staticClass:"line-numbers-wrapper"},[r("span",{staticClass:"line-number"},[a._v("1")]),r("br"),r("span",{staticClass:"line-number"},[a._v("2")]),r("br"),r("span",{staticClass:"line-number"},[a._v("3")]),r("br"),r("span",{staticClass:"line-number"},[a._v("4")]),r("br"),r("span",{staticClass:"line-number"},[a._v("5")]),r("br"),r("span",{staticClass:"line-number"},[a._v("6")]),r("br"),r("span",{staticClass:"line-number"},[a._v("7")]),r("br"),r("span",{staticClass:"line-number"},[a._v("8")]),r("br"),r("span",{staticClass:"line-number"},[a._v("9")]),r("br"),r("span",{staticClass:"line-number"},[a._v("10")]),r("br"),r("span",{staticClass:"line-number"},[a._v("11")]),r("br"),r("span",{staticClass:"line-number"},[a._v("12")]),r("br"),r("span",{staticClass:"line-number"},[a._v("13")]),r("br"),r("span",{staticClass:"line-number"},[a._v("14")]),r("br"),r("span",{staticClass:"line-number"},[a._v("15")]),r("br")])]),r("h5",{attrs:{id:"_2-3-观察跟普通的scrapy-spider的区别"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-观察跟普通的scrapy-spider的区别"}},[a._v("#")]),a._v(" 2.3 观察跟普通的scrapy.spider的区别")]),a._v(" "),r("p",[a._v("在crawlspider爬虫中，没有parse函数")]),a._v(" "),r("h5",{attrs:{id:"重点在rules中"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#重点在rules中"}},[a._v("#")]),a._v(" 重点在rules中：")]),a._v(" "),r("ol",[r("li",[a._v("rules是一个元组或者是列表，包含的是Rule对象")]),a._v(" "),r("li",[a._v("Rule表示规则，其中包含LinkExtractor,callback和follow等参数")]),a._v(" "),r("li",[a._v("LinkExtractor:连接提取器，可以通过正则或者是xpath来进行url地址的匹配")]),a._v(" "),r("li",[a._v("callback :表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调函数的处理")]),a._v(" "),r("li",[a._v("follow：连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，True表示会，Flase表示不会")])]),a._v(" "),r("h3",{attrs:{id:"_3-crawlspider腾讯招聘爬虫"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-crawlspider腾讯招聘爬虫"}},[a._v("#")]),a._v(" 3. crawlspider腾讯招聘爬虫")]),a._v(" "),r("blockquote",[r("p",[a._v("通过crawlspider爬取腾讯招聘的详情页的招聘信息")]),a._v(" "),r("p",[a._v("url："),r("a",{attrs:{href:"http://hr.tencent.com/position.php",target:"_blank",rel:"noopener noreferrer"}},[a._v("http://hr.tencent.com/position.php"),r("OutboundLink")],1)])]),a._v(" "),r("h5",{attrs:{id:"思路分析"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#思路分析"}},[a._v("#")]),a._v(" 思路分析：")]),a._v(" "),r("ol",[r("li",[a._v("定义一个规则，来进行列表页翻页，follow需要设置为True")]),a._v(" "),r("li",[a._v("定义一个规则，实现从列表页进入详情页，并且指定回调函数")]),a._v(" "),r("li",[a._v("在详情页提取数据")])]),a._v(" "),r("h5",{attrs:{id:"注意-连接提取器linkextractor中的allow对应的正则表达式匹配的是href属性的值"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#注意-连接提取器linkextractor中的allow对应的正则表达式匹配的是href属性的值"}},[a._v("#")]),a._v(" 注意：连接提取器LinkExtractor中的allow对应的正则表达式匹配的是href属性的值")]),a._v(" "),r("h3",{attrs:{id:"_4-crawlspider使用的注意点"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-crawlspider使用的注意点"}},[a._v("#")]),a._v(" 4 crawlspider使用的注意点：")]),a._v(" "),r("ol",[r("li",[a._v("除了用命令"),r("code",[a._v("scrapy genspider -t crawl <爬虫名> <allowed_domail>")]),a._v("创建一个crawlspider的模板，页可以手动创建")]),a._v(" "),r("li",[a._v("crawlspider中不能再有以parse为名的数据提取方法，该方法被crawlspider用来实现基础url提取等功能")]),a._v(" "),r("li",[a._v("Rule对象中LinkExtractor为固定参数，其他callback、follow为可选参数")]),a._v(" "),r("li",[a._v("不指定callback且follow为True的情况下，满足rules中规则的url还会被继续提取和请求")]),a._v(" "),r("li",[a._v("如果一个被提取的url满足多个Rule，那么会从rules中选择一个满足匹配条件的Rule执行")])]),a._v(" "),r("h3",{attrs:{id:"_5-了解crawlspider其他知识点"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-了解crawlspider其他知识点"}},[a._v("#")]),a._v(" 5 了解crawlspider其他知识点")]),a._v(" "),r("ul",[r("li",[r("p",[a._v("链接提取器LinkExtractor的更多常见参数")]),a._v(" "),r("ul",[r("li",[a._v("allow: 满足括号中的're'表达式的url会被提取，如果为空，则全部匹配")]),a._v(" "),r("li",[a._v("deny: 满足括号中的're'表达式的url不会被提取，优先级高于allow")]),a._v(" "),r("li",[a._v("allow_domains: 会被提取的链接的domains(url范围)，如："),r("code",[a._v("['hr.tencent.com', 'baidu.com']")])]),a._v(" "),r("li",[a._v("deny_domains: 不会被提取的链接的domains(url范围)")]),a._v(" "),r("li",[r("strong",[a._v("restrict_xpaths: 使用xpath规则进行匹配，和allow共同过滤url，即xpath满足的范围内的url地址会被提取")]),a._v("，如："),r("code",[a._v("restrict_xpaths='//div[@class=\"pagenav\"]'")])])])]),a._v(" "),r("li",[r("p",[a._v("Rule常见参数")]),a._v(" "),r("ul",[r("li",[a._v("LinkExtractor: 链接提取器，可以通过正则或者是xpath来进行url地址的匹配")]),a._v(" "),r("li",[a._v("callback: 表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调函数的处理")]),a._v(" "),r("li",[a._v("follow: 连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，默认True表示会，Flase表示不会")]),a._v(" "),r("li",[a._v("process_links: 当链接提取器LinkExtractor获取到链接列表的时候调用该参数指定的方法，这个自定义方法可以用来过滤url，且这个方法执行后才会执行callback指定的方法")])])])]),a._v(" "),r("hr"),a._v(" "),r("h3",{attrs:{id:"总结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),r("ol",[r("li",[a._v("crawlspider的作用：crawlspider可以按照规则自动获取连接")]),a._v(" "),r("li",[a._v("crawlspider爬虫的创建：scrapy genspider -t crawl tencent hr.tencent.com")]),a._v(" "),r("li",[a._v("crawlspider中rules的使用：\n"),r("ol",[r("li",[a._v("rules是一个元组或者是列表，包含的是Rule对象")]),a._v(" "),r("li",[a._v("Rule表示规则，其中包含LinkExtractor,callback和follow等参数")]),a._v(" "),r("li",[a._v("LinkExtractor:连接提取器，可以通过正则或者是xpath来进行url地址的匹配")]),a._v(" "),r("li",[a._v("callback :表示经过连接提取器提取出来的url地址响应的回调函数，可以没有，没有表示响应不会进行回调函数的处理")]),a._v(" "),r("li",[a._v("follow：连接提取器提取的url地址对应的响应是否还会继续被rules中的规则进行提取，True表示会，Flase表示不会")])])]),a._v(" "),r("li",[a._v("完成腾讯招聘爬虫crawlspider版本")])])])}),[],!1,null,null,null);s.default=e.exports}}]);