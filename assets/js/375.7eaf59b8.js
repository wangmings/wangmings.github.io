(window.webpackJsonp=window.webpackJsonp||[]).push([[375],{870:function(s,t,a){"use strict";a.r(t);var n=a(30),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"scrapy的入门使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy的入门使用"}},[s._v("#")]),s._v(" scrapy的入门使用")]),s._v(" "),a("h5",{attrs:{id:"学习目标"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标：")]),s._v(" "),a("ol",[a("li",[s._v("掌握 scrapy的安装")]),s._v(" "),a("li",[s._v("应用 创建scrapy的项目")]),s._v(" "),a("li",[s._v("应用 创建scrapy爬虫")]),s._v(" "),a("li",[s._v("应用 运行scrapy爬虫")]),s._v(" "),a("li",[s._v("应用 解析并获取scrapy爬虫中的数据")]),s._v(" "),a("li",[s._v("应用 scrapy管道的基本使用")])]),s._v(" "),a("hr"),s._v(" "),a("h3",{attrs:{id:"_1-scrapy项目实现流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-scrapy项目实现流程"}},[s._v("#")]),s._v(" 1 scrapy项目实现流程")]),s._v(" "),a("ol",[a("li",[s._v("创建一个scrapy项目:scrapy startproject mySpider")]),s._v(" "),a("li",[s._v('生成一个爬虫:scrapy genspider itcast "itcast.cn')]),s._v(" "),a("li",[s._v("提取数据:完善spider，使用xpath等方法")]),s._v(" "),a("li",[s._v("保存数据:pipeline中保存数据")])]),s._v(" "),a("h3",{attrs:{id:"_2-创建scrapy项目"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-创建scrapy项目"}},[s._v("#")]),s._v(" 2 创建scrapy项目")]),s._v(" "),a("blockquote",[a("p",[s._v("下面以抓取传智师资库来学习scrapy的入门使用："),a("a",{attrs:{href:"http://www.itcast.cn/channel/teacher.shtml",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://www.itcast.cn/channel/teacher.shtml"),a("OutboundLink")],1)])]),s._v(" "),a("p",[s._v("安装scrapy命令：sudo apt-get install scrapy 或者：pip install scrapy")]),s._v(" "),a("p",[s._v("创建scrapy项目的命令：scrapy startproject +<项目名字>")]),s._v(" "),a("p",[s._v("示例：scrapy startproject myspider")]),s._v(" "),a("p",[s._v("生成的目录和文件结果如下：")]),s._v(" "),a("p",[a("img",{attrs:{src:"/assets/images/scrapy%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8-1.png",alt:""}})]),s._v(" "),a("h3",{attrs:{id:"_3-创建爬虫"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-创建爬虫"}},[s._v("#")]),s._v(" 3 创建爬虫")]),s._v(" "),a("p",[s._v("命令："),a("strong",[s._v("在项目路径下执行")]),s._v(":scrapy genspider +<爬虫名字> + <允许爬取的域名>")]),s._v(" "),a("p",[s._v("示例：")]),s._v(" "),a("div",{staticClass:"language-Python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("cd myspider\nscrapy genspider itcast itcast"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("cn \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("生成的目录和文件结果如下：")]),s._v(" "),a("p",[a("img",{attrs:{src:"/assets/images/scrapy%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8-2.png",alt:""}})]),s._v(" "),a("h3",{attrs:{id:"_4-完善spider"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-完善spider"}},[s._v("#")]),s._v(" 4 完善spider")]),s._v(" "),a("p",[s._v("完善spider即通过方法进行数据的提取等操作")]),s._v(" "),a("p",[s._v("在/myspider/myspider/spiders/itcast.py中修改内容如下:")]),s._v(" "),a("div",{staticClass:"language-Python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" scrapy\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 自定义spider类，继承scrapy.spider")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ItcastSpider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("  \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 爬虫名字 ")]),s._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'itcast'")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 允许爬取的范围，防止爬虫爬到别的网站")]),s._v("\n    allowed_domains "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'itcast.cn'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 开始爬取的url地址")]),s._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'http://www.itcast.cn/channel/teacher.shtml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 数据提取的方法，接受下载中间件传过来的response")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" \n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# scrapy的response对象可以直接进行xpath")]),s._v("\n        names "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//div[@class=\"tea_con\"]//li/div/h3/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 获取具体数据文本的方式如下")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 分组")]),s._v("\n        li_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'//div[@class=\"tea_con\"]//li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" li_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 创建一个数据字典")]),s._v("\n            item "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 利用scrapy封装好的xpath选择器定位元素，并通过extract()或extract_first()来获取结果")]),s._v("\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.//h3/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 老师的名字")]),s._v("\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'level'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.//h4/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 老师的级别")]),s._v("\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'text'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'.//p/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 老师的介绍")]),s._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br")])]),a("h5",{attrs:{id:"注意"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[s._v("#")]),s._v(" 注意：")]),s._v(" "),a("ol",[a("li",[s._v("response.xpath方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有一些额外的方法")]),s._v(" "),a("li",[s._v("extract() 返回一个包含有字符串的列表")]),s._v(" "),a("li",[s._v("extract_first() 返回列表中的第一个字符串，列表为空没有返回None")]),s._v(" "),a("li",[s._v("spider中的parse方法必须有")]),s._v(" "),a("li",[s._v("需要抓取的url地址必须属于allowed_domains,但是start_urls中的url地址没有这个限制")]),s._v(" "),a("li",[s._v("启动爬虫的时候注意启动的位置，是在项目路径下启动")])]),s._v(" "),a("h3",{attrs:{id:"_5-利用管道pipeline来处理-保存-数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-利用管道pipeline来处理-保存-数据"}},[s._v("#")]),s._v(" 5 利用管道pipeline来处理(保存)数据")]),s._v(" "),a("h5",{attrs:{id:"_5-1-对itcast爬虫进行修改完善"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-对itcast爬虫进行修改完善"}},[s._v("#")]),s._v(" 5.1 对itcast爬虫进行修改完善")]),s._v(" "),a("p",[s._v("在爬虫文件itcast.py中parse()函数中最后添加")]),s._v(" "),a("div",{staticClass:"language-Python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("yield")]),s._v(" item \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h5",{attrs:{id:"思考-为什么要使用yield"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#思考-为什么要使用yield"}},[s._v("#")]),s._v(" 思考：为什么要使用yield？")]),s._v(" "),a("ol",[a("li",[s._v("让整个函数变成一个生成器，有什么好处呢？")]),s._v(" "),a("li",[s._v("遍历这个函数的返回值的时候，挨个把数据读到内存，不会造成内存的瞬间占用过高")]),s._v(" "),a("li",[s._v("python3中的range和python2中的xrange同理")])]),s._v(" "),a("p",[a("strong",[s._v("注意：yield能够传递的对象只能是：BaseItem,Request,dict,None")])]),s._v(" "),a("h5",{attrs:{id:"_5-2-修改pipelines-py文件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-修改pipelines-py文件"}},[s._v("#")]),s._v(" 5.2 修改pipelines.py文件")]),s._v(" "),a("div",{staticClass:"language-Python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" json\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("class")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("ItcastPipeline")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 爬虫文件中提取数据的方法每yield一次item，就会运行一次")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 该方法为固定名称函数")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("def")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("process_item")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])]),a("h5",{attrs:{id:"_5-3-在settings-py设置开启pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-3-在settings-py设置开启pipeline"}},[s._v("#")]),s._v(" 5.3 在settings.py设置开启pipeline")]),s._v(" "),a("div",{staticClass:"language-Python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("ITEM_PIPELINES "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'myspider.pipelines.ItcastPipeline'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("400")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("h3",{attrs:{id:"_6-运行scrapy"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-运行scrapy"}},[s._v("#")]),s._v(" 6 运行scrapy")]),s._v(" "),a("p",[s._v("命令：在项目目录下执行scrapy crawl +<爬虫名字>")]),s._v(" "),a("p",[s._v("示例：scrapy crawl itcast")]),s._v(" "),a("hr"),s._v(" "),a("h3",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[s._v("#")]),s._v(" 总结")]),s._v(" "),a("ol",[a("li",[s._v("rapy的安装：pip install scrapy")]),s._v(" "),a("li",[s._v("创建scrapy的项目: scrapy startproject myspider")]),s._v(" "),a("li",[s._v("创建scrapy爬虫：在项目目录下执行 scrapy genspider itcast itcast.cn")]),s._v(" "),a("li",[s._v("运行scrapy爬虫：在项目目录下执行 scrapy crawl itcast")]),s._v(" "),a("li",[s._v("解析并获取scrapy爬虫中的数据：\n"),a("ol",[a("li",[s._v("response.xpath方法的返回结果是一个类似list的类型，其中包含的是selector对象，操作和列表一样，但是有一些额外的方法")]),s._v(" "),a("li",[s._v("extract() 返回一个包含有字符串的列表")]),s._v(" "),a("li",[s._v("extract_first() 返回列表中的第一个字符串，列表为空没有返回None")])])]),s._v(" "),a("li",[s._v("scrapy管道的基本使用:\n"),a("ol",[a("li",[s._v("完善pipelines.py中的process_item函数")]),s._v(" "),a("li",[s._v("在settings.py中设置开启pipeline")])])])])])}),[],!1,null,null,null);t.default=e.exports}}]);