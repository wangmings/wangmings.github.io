(window.webpackJsonp=window.webpackJsonp||[]).push([[374],{869:function(s,a,r){"use strict";r.r(a);var t=r(30),e=Object(t.a)({},(function(){var s=this,a=s.$createElement,r=s._self._c||a;return r("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[r("h2",{attrs:{id:"scrapy的概念和流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#scrapy的概念和流程"}},[s._v("#")]),s._v(" scrapy的概念和流程")]),s._v(" "),r("h5",{attrs:{id:"学习目标"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#学习目标"}},[s._v("#")]),s._v(" 学习目标：")]),s._v(" "),r("ol",[r("li",[s._v("了解 scrapy的概念")]),s._v(" "),r("li",[s._v("掌握 scrapy框架的运行流程")]),s._v(" "),r("li",[s._v("掌握 scrapy框架的作用")])]),s._v(" "),r("hr"),s._v(" "),r("h3",{attrs:{id:"_1-为什么学习scrapy"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-为什么学习scrapy"}},[s._v("#")]),s._v(" 1 为什么学习scrapy？")]),s._v(" "),r("ol",[r("li",[s._v("scrapy不能解决剩下的10%的爬虫需求")]),s._v(" "),r("li",[s._v("能够让开发过程方便、快速")]),s._v(" "),r("li",[s._v("scrapy框架能够让我们的爬虫效率更高")])]),s._v(" "),r("h3",{attrs:{id:"_2-什么是scrapy"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-什么是scrapy"}},[s._v("#")]),s._v(" 2 什么是scrapy？")]),s._v(" "),r("p",[s._v("文档地址："),r("a",{attrs:{href:"http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/overview.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/overview.html"),r("OutboundLink")],1)]),s._v(" "),r("p",[s._v("Scrapy 使用了Twisted['twɪstɪd]异步网络框架，可以加快我们的下载速度。")]),s._v(" "),r("p",[r("strong",[s._v("Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架")]),s._v("，我们只需要实现少量的代码，就能够快速的抓取。")]),s._v(" "),r("h3",{attrs:{id:"_3-异步和非阻塞的区别"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-异步和非阻塞的区别"}},[s._v("#")]),s._v(" 3 异步和非阻塞的区别")]),s._v(" "),r("p",[s._v("前面我们说Twisted是一个异步的网络框架，经常我们也听到一个词语叫做非阻塞，那么他们有什么区别呢？")]),s._v(" "),r("p",[r("img",{attrs:{src:"/assets/images/%E5%90%8C%E6%AD%A5%E5%92%8C%E5%BC%82%E6%AD%A5.png",alt:""}})]),s._v(" "),r("p",[r("strong",[s._v("异步")]),s._v("：调用在发出之后，这个调用就直接返回，不管有无结果；异步是过程。 "),r("strong",[s._v("非阻塞")]),s._v("：关注的是程序在等待调用结果（消息，返回值）时的状态，指在不能立刻得到结果之前，该调用不会阻塞当前线程。")]),s._v(" "),r("h3",{attrs:{id:"_4-scrapy的工作流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-scrapy的工作流程"}},[s._v("#")]),s._v(" 4 scrapy的工作流程")]),s._v(" "),r("h5",{attrs:{id:"_4-1-回顾之前的爬虫流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-回顾之前的爬虫流程"}},[s._v("#")]),s._v(" 4.1 回顾之前的爬虫流程")]),s._v(" "),r("p",[r("img",{attrs:{src:"/assets/images/%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B-1.png",alt:""}})]),s._v(" "),r("h5",{attrs:{id:"_4-2-上面的流程可以改写为"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-上面的流程可以改写为"}},[s._v("#")]),s._v(" 4.2 上面的流程可以改写为")]),s._v(" "),r("p",[r("img",{attrs:{src:"/assets/images/%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B-2.png",alt:""}})]),s._v(" "),r("h5",{attrs:{id:"_4-3-scrapy的流程"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-scrapy的流程"}},[s._v("#")]),s._v(" 4.3 scrapy的流程")]),s._v(" "),r("p",[r("img",{attrs:{src:"/assets/images/%E7%88%AC%E8%99%AB%E6%B5%81%E7%A8%8B-3.png",alt:""}})]),s._v(" "),r("h5",{attrs:{id:"其流程可以描述如下"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#其流程可以描述如下"}},[s._v("#")]),s._v(" 其流程可以描述如下：")]),s._v(" "),r("ol",[r("li",[s._v("调度器把requests--\x3e引擎--\x3e下载中间件---\x3e下载器")]),s._v(" "),r("li",[s._v("下载器发送请求，获取响应----\x3e下载中间件----\x3e引擎---\x3e爬虫中间件---\x3e爬虫")]),s._v(" "),r("li",[s._v("爬虫提取url地址，组装成request对象----\x3e爬虫中间件---\x3e引擎---\x3e调度器")]),s._v(" "),r("li",[s._v("爬虫提取数据---\x3e引擎---\x3e管道")]),s._v(" "),r("li",[s._v("管道进行数据的处理和保存")])]),s._v(" "),r("h5",{attrs:{id:"注意"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#注意"}},[s._v("#")]),s._v(" 注意：")]),s._v(" "),r("ul",[r("li",[s._v("图中绿色线条的表示数据的传递")]),s._v(" "),r("li",[s._v("注意图中中间件的位置，决定了其作用")]),s._v(" "),r("li",[s._v("注意其中引擎的位置，所有的模块之前相互独立，只和引擎进行交互")])]),s._v(" "),r("h5",{attrs:{id:"_4-4-scrapy中每个模块的具体作用"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-scrapy中每个模块的具体作用"}},[s._v("#")]),s._v(" 4.4 scrapy中每个模块的具体作用")]),s._v(" "),r("p",[r("img",{attrs:{src:"/assets/images/scrapy%E7%BB%84%E4%BB%B6.png",alt:""}})]),s._v(" "),r("hr"),s._v(" "),r("h3",{attrs:{id:"小结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[s._v("#")]),s._v(" 小结")]),s._v(" "),r("ol",[r("li",[s._v("scrapy的概念：Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架")]),s._v(" "),r("li",[s._v("scrapy框架的运行流程以及数据传递过程：\n"),r("ol",[r("li",[s._v("调度器把requests--\x3e引擎--\x3e下载中间件---\x3e下载器")]),s._v(" "),r("li",[s._v("下载器发送请求，获取响应----\x3e下载中间件----\x3e引擎---\x3e爬虫中间件---\x3e爬虫")]),s._v(" "),r("li",[s._v("爬虫提取url地址，组装成request对象----\x3e爬虫中间件---\x3e引擎---\x3e调度器")]),s._v(" "),r("li",[s._v("爬虫提取数据---\x3e引擎---\x3e管道")]),s._v(" "),r("li",[s._v("管道进行数据的处理和保存")])])]),s._v(" "),r("li",[s._v("scrapy框架的作用：通过少量代码实现快速抓取")]),s._v(" "),r("li",[s._v("掌握scrapy中每个模块的作用： 引擎(engine)：负责数据和信号在不腰痛模块间的传递 调度器(scheduler)：实现一个队列，存放引擎发过来的request请求对象 下载器(downloader)：发送引擎发过来的request请求，获取响应，并将响应交给引擎 爬虫(spider)：处理引擎发过来的response，提取数据，提取url，并交给引擎 管道(pipeline)：处理引擎传递过来的数据，比如存储 下载中间件(downloader middleware)：可以自定义的下载扩展，比如设置代理ip 爬虫中间件(spider middleware)：可以自定义request请求和进行response过滤")]),s._v(" "),r("li",[s._v("理解异步和非阻塞的区别：异步是过程，非阻塞是状态")])])])}),[],!1,null,null,null);a.default=e.exports}}]);